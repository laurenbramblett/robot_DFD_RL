{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b848632",
   "metadata": {},
   "source": [
    "# Automation Notebook for Feature Preprocessing And Model Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c57a2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ecc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier #Deprecated\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba02379",
   "metadata": {},
   "source": [
    "**Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fbb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNN(layer_params=[],compile_params=[[],{'loss':'mean_squared_error', 'optimizer':'adam', 'metrics':['mse']}],model=Sequential):\n",
    "    \"\"\"Construct an arbitrary Keras layered model\n",
    "        layer_params and compile params must have form list(iterable(list,dict)), \n",
    "            ex: [[[layer1_args],{layer1_kwarg1:val,layer1_kwarg2:val}],\n",
    "                [[layer2_args],{layer2_kwarg1:val,layer2_kwarg2:val}]]\n",
    "            While this may seem cumbersome, it provides full flexibility in creating the model object\n",
    "    \"\"\"\n",
    "    model=model()\n",
    "    for i in range(len(layer_params)):\n",
    "        args=layer_params[i][0]\n",
    "#         print(args)\n",
    "        kwargs=layer_params[i][1]\n",
    "#         print(kwargs)\n",
    "        model.add(Dense(*args,**kwargs))\n",
    "    model.compile(*compile_params[0],**compile_params[1])\n",
    "    return model\n",
    "\n",
    "def bulk_layers(n,layer_params):\n",
    "    \"\"\"Construct appropriate input dicts for bulk of the same layer\"\"\"\n",
    "    return [layer_params for i in range(n)]\n",
    "\n",
    "\n",
    "\n",
    "def get_driver_layers(HL_scale,input_dim,activation='relu',base=64):\n",
    "    \"\"\"Construct layer_params for createNN() in accordance with the NN architecture we want for our controller\n",
    "        Layer0: base # neurons, input dim set to match features\n",
    "        Layer1-3: base*HL_scale neurons\n",
    "        Layer4: 1 output, linear activation. Always used to produce the final angle for the controller\n",
    "    \"\"\"\n",
    "    layers=[[[base], {'input_dim':input_dim, 'activation':activation}],\n",
    "[[base*HL_scale], {'activation':activation}],\n",
    "[[base*HL_scale], {'activation':activation}],\n",
    "[[1], {'activation':'linear'}]]\n",
    "    return layers\n",
    "\n",
    "def simulate_model(model,worlds):\n",
    "    \"\"\"runs the simulator with a given model, along a set of worlds. returns the total number of succesful runs, along with a world by world Pass/Fail\"\"\"\n",
    "    world_pf={}\n",
    "    world_c_iters={}\n",
    "    pf_sum=0\n",
    "    for w in worlds:\n",
    "        pas=np.random.choice([1,0]) ###Put real simulator call here\n",
    "        ctrl_iters=np.random.randint(100)\n",
    "        world_pf[w]=pas\n",
    "        world_c_iters[w]=ctrl_iters\n",
    "        pf_sum+=pas\n",
    "    avg_ctrl_iters=np.array(list(world_c_iters.values())).mean()\n",
    "    return pf_sum,avg_ctrl_iters,world_pf,world_c_iters\n",
    "\n",
    "\n",
    "#We ultimately opted for a grid search rather than a random search,but this func facilitates the latter\n",
    "def get_random_model(layer_sizes,activations,depth,input_dim,output_dim,compile_params=[[],{'loss':'mean_squared_error', 'optimizer':'adam', 'metrics':['mse']}]):\n",
    "    rng=np.random.default_rng()\n",
    "    lyrs=rng.choice(layer_sizes,size=depth)\n",
    "    activ=rng.choice(activations,size=depth+1)\n",
    "    layers=[[[lyrs[0]],{'input_dim':input_dim,'activation':activ[0]}]] #create input layer\n",
    "    for i in range(1,depth):\n",
    "        layers.append([[lyrs[i]],{'activation':activ[i]}])\n",
    "    layers.append([[1],{'activation':activ[-1]}]) #create output layer\n",
    "    \n",
    "    return layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12fc65",
   "metadata": {},
   "source": [
    "**Read in Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c052af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=pd.read_csv('ObsRecordUniformRandom_v5.csv')\n",
    "# world_data=pd.read_csv('characteristics_by_world.csv')\n",
    "lidar_list = [\"Lidar\"+str(x) for x in range(0,32)]\n",
    "state_list = [\"goalDist\",\"goalAng\",\"forceAng\",\"World\"]\n",
    "headers = lidar_list + state_list\n",
    "raw_data.columns=headers\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1514cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60add34",
   "metadata": {},
   "source": [
    "**Preprocessing and Test-Train Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac=2/3 #fraction of data to train on\n",
    "ttr=(1-train_frac)/train_frac #train_test_ratio: 2 training worlds for each test world\n",
    "\n",
    "world_ids=range(1,1+len(raw_data['World'].unique()))\n",
    "test_world_ids=[w for w in world_ids if w%(ttr+1)==0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf3351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = pp.MinMaxScaler()\n",
    "normalized_data=pd.DataFrame(min_max_scaler.fit_transform(raw_data.values),columns=headers)\n",
    "normalized_data['World']=raw_data['World']\n",
    "\n",
    "\n",
    "test_data=normalized_data[normalized_data['World'].isin(test_world_ids)]\n",
    "train_data=normalized_data[~normalized_data['World'].isin(test_world_ids)]\n",
    "\n",
    "\n",
    "targets_l=['forceAng']\n",
    "features_l=headers.copy()\n",
    "features_l.remove('forceAng')\n",
    "features_l.remove('World')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b67840",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "**Hyperparameter Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc55ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes=[32,64,128]\n",
    "HL_scales=[1,2,3,4]\n",
    "optimizers=['SGD','Adam']\n",
    "learning_rates=[0.1,0.01,0.001]\n",
    "epochs=100\n",
    "\n",
    "#Restricted set for faster automation testing\n",
    "# batch_sizes=[128]\n",
    "# HL_scales=[1,2]\n",
    "# optimizers=['SGD','Adam']\n",
    "# learning_rates=[0.1]\n",
    "# epochs=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c45af9",
   "metadata": {},
   "source": [
    "**Grid Search**\n",
    "\n",
    "With the nonstandard model construction employed, we opted to write our own loop rather than using sklearn's GridSearchCV SciKeras, or Keras' own methods. While it may be possible to do so, this was flexible to our evolving approach and scaled sufficiently for our pruposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "score_dict={}\n",
    "\n",
    "\n",
    "mn=1\n",
    "for b_sz in batch_sizes:\n",
    "    for hl_scale in HL_scales:\n",
    "        for lr in learning_rates:\n",
    "            for opt in optimizers:\n",
    "                opti=None\n",
    "                if opt=='Adam': #This makes indexing easier later,\n",
    "                    opti=Adam(learning_rate=lr)\n",
    "                if opt=='SGD':\n",
    "                    opti=SGD(learning_rate=lr)\n",
    "                test_params=(b_sz,hl_scale,lr,opt)\n",
    "                print(\"\\n Model No. %d\"%mn)\n",
    "                print(test_params)\n",
    "                layers=get_driver_layers(hl_scale,len(features_l),'relu')\n",
    "                compile_params=[[],{'loss':'mean_squared_error', 'optimizer':opti, 'metrics':['mse']}]\n",
    "                model=createNN(layer_params=layers,compile_params=compile_params)\n",
    "                model.fit(train_data[features_l],train_data[targets_l],epochs=epochs,batch_size=b_sz)\n",
    "                \n",
    "                _,trn_score=model.evaluate(train_data[features_l],train_data[targets_l])\n",
    "\n",
    "                _,test_score=model.evaluate(test_data[features_l],test_data[targets_l])\n",
    "\n",
    "                pf_sum,avg_ctrl_iters,pf_by_world,ctrl_iters_by_world=simulate_model(model,test_world_ids)\n",
    "\n",
    "                results[test_params]={'layers':layers,'model':model,\n",
    "                                      'training score':trn_score,'test score':test_score,\n",
    "                                      'pf_score':pf_sum,'pf_by_world':pf_by_world,\n",
    "                                      'avg_ctrl_iters':avg_ctrl_iters,'ctrl_iters_by_world':ctrl_iters_by_world}\n",
    "                print(test_score)\n",
    "                score_dict[test_params]=[trn_score,test_score,pf_sum,avg_ctrl_iters]\n",
    "                mn+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291528a",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe75a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results #Uncomment if you want to see a really long and not amazingly helpful variable string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=score_dict.keys()\n",
    "vals=[score_dict[i] for i in idx]\n",
    "idx\n",
    "Score_df=pd.DataFrame(vals,index=idx,columns=['Training Score','Testing Score','NN Controller Pass Count','NN AVG Controller Iterations'])\n",
    "Score_df.index.names=['Batch Size','HL_Scaler','Learning Rate','Optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Score_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e270c4d",
   "metadata": {},
   "source": [
    "**Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Score_df.to_csv('scores.csv')\n",
    "\n",
    "import pickle\n",
    "with open('result_dict.txt','wb') as fh:\n",
    "    pickle.dump(results,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c17ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26814c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
